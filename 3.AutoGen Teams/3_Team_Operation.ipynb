{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4dbda135",
   "metadata": {},
   "source": [
    "## Team Operation: Reset, Stop, Resume and Abort\n",
    "- to take more control like a teamlead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a380815",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py:413: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "key = os.getenv(\"Groq_api_key\")\n",
    "\n",
    "model_client =  OpenAIChatCompletionClient(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key = key,\n",
    "    model_info={\n",
    "        \"family\":'llama',\n",
    "        \"vision\" :False,\n",
    "        \"function_calling\":True,\n",
    "        \"json_output\": True\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 3 AGENTS\n",
    "add_1_agent_first = AssistantAgent(\n",
    "    name=\"add_1_agent_first\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"add 1 to number which is given to you as input and give out resultant number. start with 0 if no input is given\"\n",
    ")\n",
    "\n",
    "add_1_agent_second = AssistantAgent(\n",
    "    name=\"add_1_agent_second\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"add 1 to number which you got from previous agent and give resultant number.\"\n",
    ")\n",
    "\n",
    "add_1_agent_third = AssistantAgent(\n",
    "    name=\"add_1_agent_third\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"add 1 to number which you got from previous agent and give resultant number.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9fa64ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEAM CREATED\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [add_1_agent_first, add_1_agent_second, add_1_agent_third], # list of agents \n",
    "    max_turns=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d21cf8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "first number is 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The number given is 5. Adding 1 to it makes it 6.\n",
      "\n",
      "Resultant number: 6\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The number given is 6. Adding 1 to it makes it 7.\n",
      "\n",
      "Resultant number: 7\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "The number given is 7. Adding 1 to it makes it 8.\n",
      "\n",
      "Resultant number: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='first number is 5', type='TextMessage'), TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=160, completion_tokens=24), metadata={}, content='The number given is 5. Adding 1 to it makes it 6.\\n\\nResultant number: 6', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=177, completion_tokens=24), metadata={}, content='The number given is 6. Adding 1 to it makes it 7.\\n\\nResultant number: 7', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=205, completion_tokens=24), metadata={}, content='The number given is 7. Adding 1 to it makes it 8.\\n\\nResultant number: 8', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(team.run_stream(task= \"first number is 5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5da120",
   "metadata": {},
   "source": [
    "## Resuming a Team\n",
    "Teams are stateful and maintains the conversation history and context after each run, unless you reset the team.\n",
    "\n",
    "\n",
    "We can resume a team to continue from where it left off by calling the run() or run_stream() method without a **new task**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec976595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "The number given is 8. Adding 1 to it makes it 9.\n",
      "\n",
      "Resultant number: 9\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The number given is 9. Adding 1 to it makes it 10.\n",
      "\n",
      "Resultant number: 10\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "The number given is 10. Adding 1 to it makes it 11.\n",
      "\n",
      "Resultant number: 11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=244, completion_tokens=24), metadata={}, content='The number given is 8. Adding 1 to it makes it 9.\\n\\nResultant number: 9', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=261, completion_tokens=24), metadata={}, content='The number given is 9. Adding 1 to it makes it 10.\\n\\nResultant number: 10', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=289, completion_tokens=24), metadata={}, content='The number given is 10. Adding 1 to it makes it 11.\\n\\nResultant number: 11', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await Console(team.run_stream()) # first it will continue with the previous state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635fe70f",
   "metadata": {},
   "source": [
    "### team resumed from where it left off in the output above, and the first message is from the next agent after the last agent that spoke before the team stopped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d0fbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "What was the largest number you got in the result?\n",
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "Let me recall the sequence:\n",
      "\n",
      "The sequence started with 0, and then it went as follows: \n",
      "0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11.\n",
      "\n",
      "The largest number I got in the result was 11.\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "The correct sequence was indeed: 0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11.\n",
      "\n",
      "And yes, the largest number you got in the result was indeed 11. \n",
      "\n",
      "However, I noticed that the sequence initially started with 0, then after 3, it jumped to 5 instead of 4. It would be more logical if the sequence had continued from 3 to 4.\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "You're right, the sequence did jump from 3 to 5, skipping 4. The correct sequence should have been:\n",
      "\n",
      "0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\n",
      "\n",
      "If we had continued the sequence correctly, the largest number I would have gotten in the result would still be 11, but the sequence would have been more logical and consistent. Thank you for pointing that out and helping me improve!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='What was the largest number you got in the result?', type='TextMessage'), TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=344, completion_tokens=66), metadata={}, content='Let me recall the sequence:\\n\\nThe sequence started with 0, and then it went as follows: \\n0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11.\\n\\nThe largest number I got in the result was 11.', type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=403, completion_tokens=102), metadata={}, content='The correct sequence was indeed: 0, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11.\\n\\nAnd yes, the largest number you got in the result was indeed 11. \\n\\nHowever, I noticed that the sequence initially started with 0, then after 3, it jumped to 5 instead of 4. It would be more logical if the sequence had continued from 3 to 4.', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=509, completion_tokens=108), metadata={}, content=\"You're right, the sequence did jump from 3 to 5, skipping 4. The correct sequence should have been:\\n\\n0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11\\n\\nIf we had continued the sequence correctly, the largest number I would have gotten in the result would still be 11, but the sequence would have been more logical and consistent. Thank you for pointing that out and helping me improve!\", type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "  # second we can give a new task and it will have idea about previous task\n",
    "await Console(team.run_stream(task = 'What was the largest number you got in the result?'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d266266",
   "metadata": {},
   "source": [
    "## Reset our Team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66e9f069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "Since no input is given, I'll start with 0. \n",
      "\n",
      "0 + 1 = 1\n",
      "\n",
      "The resultant number is: 1\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "Since the previous number was 1, I will add 1 to it.\n",
      "\n",
      "1 + 1 = 2\n",
      "\n",
      "The resultant number is: 2\n",
      "---------- TextMessage (add_1_agent_third) ----------\n",
      "Since the previous number was 2, I will add 1 to it.\n",
      "\n",
      "2 + 1 = 3\n",
      "\n",
      "The resultant number is: 3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='add_1_agent_first', models_usage=RequestUsage(prompt_tokens=57, completion_tokens=30), metadata={}, content=\"Since no input is given, I'll start with 0. \\n\\n0 + 1 = 1\\n\\nThe resultant number is: 1\", type='TextMessage'), TextMessage(source='add_1_agent_second', models_usage=RequestUsage(prompt_tokens=80, completion_tokens=32), metadata={}, content='Since the previous number was 1, I will add 1 to it.\\n\\n1 + 1 = 2\\n\\nThe resultant number is: 2', type='TextMessage'), TextMessage(source='add_1_agent_third', models_usage=RequestUsage(prompt_tokens=116, completion_tokens=32), metadata={}, content='Since the previous number was 2, I will add 1 to it.\\n\\n2 + 1 = 3\\n\\nThe resultant number is: 3', type='TextMessage')], stop_reason='Maximum number of turns 3 reached.')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await team.reset() # on_reset() on all agents\n",
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f787b68",
   "metadata": {},
   "source": [
    "### for STOP learn TERMINATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f829b1",
   "metadata": {},
   "source": [
    "## Aborting A Team\n",
    "- Different from stopping a team, aborting a team will immediately stop the team and raise a CancelledError exception.\n",
    "\n",
    "## **DONE IN TERMINATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d22c06a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
