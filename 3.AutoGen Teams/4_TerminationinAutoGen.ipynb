{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2994483e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51f3240c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py:413: UserWarning: Missing required field 'structured_output' in ModelInfo. This field will be required in a future version of AutoGen.\n",
      "  validate_model_info(self._model_info)\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "\n",
    "key = \"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\"\n",
    "\n",
    "model_client =  OpenAIChatCompletionClient(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    model=\"deepseek/deepseek-chat-v3-0324:free\",\n",
    "    api_key = key,\n",
    "    model_info={\n",
    "        \"family\":'deepseek',\n",
    "        \"vision\" :True,\n",
    "        \"function_calling\":True,\n",
    "        \"json_output\": False\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "# 3 AGENTS\n",
    "add_1_agent_first = AssistantAgent(\n",
    "    name=\"add_1_agent_first\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"add 1 to number which is given to you as input and give output just resultant number nothing extra just a number as output. start with 0 if no input is given\"\n",
    ")\n",
    "\n",
    "add_1_agent_second = AssistantAgent(\n",
    "    name=\"add_1_agent_second\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"add 1 to number which you got from previous agent and just give resultant number.\"\n",
    ")\n",
    "\n",
    "add_1_agent_third = AssistantAgent(\n",
    "    name=\"add_1_agent_third\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"add 1 to number which you got from previous agent and just give resultant number.\"\n",
    ")\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a900d875",
   "metadata": {},
   "outputs": [],
   "source": [
    "team = RoundRobinGroupChat(\n",
    "    [add_1_agent_first, add_1_agent_second, add_1_agent_third], # list of agents \n",
    "    #max_turns=3 # MAY BE THIS WILL BE NOT BE VALID IN ALL THE CASES SO, it make take lot of time so we use termination conditions\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de07302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "To solve this problem, we need to write a program that takes an input number, adds 1 to it, and returns the result. If no input is provided, the program should start with 0 (which effectively returns 1 after adding 1). The output should be just the resultant number without any additional text or formatting.\n",
      "\n",
      "### Approach\n",
      "1. **Handle Input**: The program needs to check if an input number is provided. If it's not provided, it should default to 0.\n",
      "2. **Add One**: The provided number (or 0 if none is given) is then incremented by 1.\n",
      "3. **Output the Result**: The result of the addition is printed out as a plain number with no extra characters or formatting.\n",
      "\n",
      "### Solution Code\n",
      "```python\n",
      "import sys\n",
      "\n",
      "# Read input from stdin. The problem likely expects input to be passed in some way, here handling command line input or first argument.\n",
      "input_str = sys.stdin.read().strip()\n",
      "\n",
      "if input_str == \"\":\n",
      "    num = 0\n",
      "else:\n",
      "    try:\n",
      "        num = int(input_str)\n",
      "    except ValueError:\n",
      "        num = 0  # Assuming if input is invalid, treat as 0, though problem specifies \"number given as input\"\n",
      "\n",
      "result = num + 1\n",
      "print(result)\n",
      "```\n",
      "\n",
      "### Explanation\n",
      "1. **Reading Input**: The code reads the entire input from stdin and strips any surrounding whitespace. If the input is empty (no input provided), it defaults to 0.\n",
      "2. **Handling Numeric Input**: If there is input, it attempts to convert it to an integer. This handles cases where the input might not be a number, although according to the problem statement, the input is a number. If conversion fails, it falls back to 0, but in the context of the problem, the input should always be a valid number or absent.\n",
      "3. **Computing Result**: The code then adds 1 to the number (or 0 if no input was provided) and prints the result as a simple integer output.\n",
      "\n",
      "This approach ensures that the program correctly handles both cases (with and without input) and produces the desired output exactly as specified.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "await Console(team.run_stream())  # this will not stop as no termination instruction given"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00aaf1c",
   "metadata": {},
   "source": [
    "### Termination Consitions\n",
    "-  However, a run can go on forever, and in many cases, we need to know when to stop them. This is the role of the termination condition.\n",
    "- Some important things to note about termination conditions:\n",
    "    - They are stateful but reset automatically after each run (run() or run_stream()) is finished.\n",
    "    - They can be combined using the AND and OR operators.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d39d15d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.teams import RoundRobinGroupChat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7866c55",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'add_1_agent_first' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mautogen_agentchat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconditions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MaxMessageTermination\n\u001b[0;32m      2\u001b[0m max_message \u001b[38;5;241m=\u001b[39m MaxMessageTermination(\u001b[38;5;241m5\u001b[39m)\n\u001b[0;32m      4\u001b[0m team \u001b[38;5;241m=\u001b[39m RoundRobinGroupChat(\n\u001b[1;32m----> 5\u001b[0m     [\u001b[43madd_1_agent_first\u001b[49m, add_1_agent_second, add_1_agent_third], \u001b[38;5;66;03m# list of agents \u001b[39;00m\n\u001b[0;32m      6\u001b[0m     termination_condition \u001b[38;5;241m=\u001b[39m max_message\n\u001b[0;32m      7\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'add_1_agent_first' is not defined"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.conditions import MaxMessageTermination\n",
    "max_message = MaxMessageTermination(5)\n",
    "\n",
    "team = RoundRobinGroupChat(\n",
    "    [add_1_agent_first, add_1_agent_second, add_1_agent_third], # list of agents \n",
    "    termination_condition = max_message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7df4410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (add_1_agent_first) ----------\n",
      "### Understanding the Problem\n",
      "\n",
      "First, I need to clearly understand what the problem is asking. The problem statement is:\n",
      "\n",
      "**\"Add 1 to a number which is given to you as input and give out the resultant number. Start with 0 if no input is given.\"**\n",
      "\n",
      "Breaking this down:\n",
      "1. **Input**: A number, which may or may not be provided.\n",
      "2. **Output**: The result of adding 1 to the input number. If no input is provided, the output should be 0 + 1 = 1.\n",
      "\n",
      "But the last part seems a bit confusing: \"Start with 0 if no input is given.\" \n",
      "\n",
      "- Does it mean that if no input is given, we should consider the input as 0 and add 1 to it, resulting in 1?\n",
      "- Or does it mean we should return 0 when no input is given?\n",
      "\n",
      "Looking at the phrasing: \"add 1 to number... and give out just resultant number. start with 0 if no input is given.\"\n",
      "\n",
      "It's more natural to interpret it as: If there's no input, start by assuming the number is 0, then add 1 to it and return the result (which would be 1). \n",
      "\n",
      "But it's a bit ambiguous. To clarify, I think the problem means to take a number as input, add 1 to it, and return the result. If no input is provided, default the input to 0, add 1, and return 1.\n",
      "\n",
      "### Examples to Illustrate\n",
      "\n",
      "To ensure clarity, let's consider a few examples:\n",
      "\n",
      "1. **Input**: 5\n",
      "   - Add 1: 5 + 1 = 6\n",
      "   - Output: 6\n",
      "\n",
      "2. **Input**: -3\n",
      "   - Add 1: -3 + 1 = -2\n",
      "   - Output: -2\n",
      "\n",
      "3. **No Input**:\n",
      "   - Default input to 0\n",
      "   - Add 1: 0 + 1 = 1\n",
      "   - Output: 1\n",
      "\n",
      "### Approach to Solution\n",
      "\n",
      "I need to write a function that:\n",
      "1. Takes an optional number as input.\n",
      "2. If the input is not provided, treats it as 0.\n",
      "3. Adds 1 to the input (or the default 0).\n",
      "4. Returns the result.\n",
      "\n",
      "### Potential Edge Cases\n",
      "\n",
      "1. **No Input**: As mentioned, default to 0, then add 1.\n",
      "2. **Non-number Input**: The problem mentions \"number,\" but what if a non-number is passed? For the sake of this problem, we can assume the input is always a valid number or not provided.\n",
      "3. **Floating Point Numbers**: For example, input 3.5 → output 4.5.\n",
      "\n",
      "### Implementation Steps\n",
      "\n",
      "1. **Check if input is provided**: In many programming languages, functions can have default parameters.\n",
      "2. **Default to 0 if no input**: Use a default parameter value.\n",
      "3. **Add 1 to the input**: Simple arithmetic operation.\n",
      "4. **Return the result**.\n",
      "\n",
      "### Writing the Function\n",
      "\n",
      "Let me try to write this in pseudocode first:\n",
      "\n",
      "```\n",
      "function addOne(input = 0):\n",
      "    return input + 1\n",
      "```\n",
      "\n",
      "- `input = 0` : This sets the default value of input to 0 if no argument is passed.\n",
      "\n",
      "### Testing the Function\n",
      "\n",
      "1. `addOne(5)` → 5 + 1 = 6 ✓\n",
      "2. `addOne(-3)` → -3 + 1 = -2 ✓\n",
      "3. `addOne()` → 0 + 1 = 1 ✓\n",
      "4. `addOne(0)` → 0 + 1 = 1 ✓\n",
      "5. `addOne(3.5)` → 3.5 + 1 = 4.5 ✓\n",
      "\n",
      "All test cases pass, confirming the function works as intended.\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "Based on the above reasoning, the function can be implemented in various programming languages. Here's how it might look in a few common ones:\n",
      "\n",
      "- **JavaScript**:\n",
      "  ```javascript\n",
      "  function addOne(input = 0) {\n",
      "      return input + 1;\n",
      "  }\n",
      "  ```\n",
      "\n",
      "- **Python**:\n",
      "  ```python\n",
      "  def add_one(input=0):\n",
      "      return input + 1\n",
      "  ```\n",
      "\n",
      "- **Java**: Java doesn't support default parameters directly, but we can use method overloading or check for null.\n",
      "  ```java\n",
      "  public int addOne(Integer input) {\n",
      "      return (input == null ? 0 : input) + 1;\n",
      "  }\n",
      "  ```\n",
      "\n",
      "Since the problem statement doesn't specify a language, the key takeaway is the logic: default the input to 0 if not provided, then add 1 and return the result.\n",
      "\n",
      "### Verification\n",
      "\n",
      "Let me verify once more with the initial problem statement:\n",
      "\n",
      "- **Given input**: Add 1 → correct.\n",
      "- **No input**: Default to 0, add 1 → output 1.\n",
      "\n",
      "This matches the problem's requirements.\n",
      "\n",
      "### Final Thought\n",
      "\n",
      "The problem is quite straightforward, but it's essential to handle the case where no input is provided. The use of default parameters makes the solution clean and concise.\n",
      "\n",
      "\\boxed{ \\text{The function should add 1 to the input number, defaulting the input to 0 if none is provided, thus returning } \\text{input} + 1 \\text{ or } 1 \\text{ if no input is given.} }\n",
      "---------- TextMessage (add_1_agent_second) ----------\n",
      "### Understanding the Problem\n",
      "\n",
      "The problem states: \n",
      "\"add 1 to number which you got from previous agent and just give resultant number.\"\n",
      "\n",
      "Additionally, there's a note: \"start with 0 if no input is given.\"\n",
      "\n",
      "From this, I interpret that:\n",
      "1. There might be an input number provided (presumably from a \"previous agent\").\n",
      "2. If no input is provided, we should assume the starting number is 0.\n",
      "3. We need to add 1 to this number and return the result.\n",
      "\n",
      "### Breaking It Down\n",
      "\n",
      "**Step 1: Check for Input**\n",
      "- First, we need to determine if an input number is given.\n",
      "- If no input is provided, we should start with 0.\n",
      "\n",
      "**Step 2: Perform the Addition**\n",
      "- Take the input number (or 0 if none is given) and add 1 to it.\n",
      "\n",
      "**Step 3: Return the Result**\n",
      "- Output the result of the addition.\n",
      "\n",
      "### Edge Cases to Consider\n",
      "\n",
      "1. **No Input Provided**: As per the note, start with 0.\n",
      "2. **Negative Numbers**: Adding 1 should work correctly (e.g., -5 + 1 = -4).\n",
      "3. **Non-integer Numbers**: For example, 3.5 + 1 = 4.5.\n",
      "4. **Zero Input**: 0 + 1 = 1.\n",
      "\n",
      "### Implementation Approach\n",
      "\n",
      "I'll think of this in terms of a function that takes an optional input parameter.\n",
      "\n",
      "**Pseudocode**:\n",
      "```\n",
      "function addOne(input):\n",
      "    if input is not provided:\n",
      "        input = 0\n",
      "    result = input + 1\n",
      "    return result\n",
      "```\n",
      "\n",
      "### Testing the Solution\n",
      "\n",
      "Let's verify with different scenarios:\n",
      "\n",
      "1. **No Input**:\n",
      "   - input: not provided → defaults to 0.\n",
      "   - 0 + 1 = 1 → output: 1.\n",
      "\n",
      "2. **Input is 5**:\n",
      "   - 5 + 1 = 6 → output: 6.\n",
      "\n",
      "3. **Input is -3**:\n",
      "   - -3 + 1 = -2 → output: -2.\n",
      "\n",
      "4. **Input is 0**:\n",
      "   - 0 + 1 = 1 → output: 1.\n",
      "\n",
      "5. **Input is 2.5**:\n",
      "   - 2.5 + 1 = 3.5 → output: 3.5.\n",
      "\n",
      "All these cases seem to work correctly.\n",
      "\n",
      "### Final Answer\n",
      "\n",
      "Based on the above reasoning, the solution can be implemented in various programming languages. Here's how it might look in Python:\n",
      "\n",
      "```python\n",
      "def add_one(number=0):\n",
      "    return number + 1\n",
      "```\n",
      "\n",
      "- **Explanation**: \n",
      "  - The function `add_one` takes an optional parameter `number` with a default value of 0.\n",
      "  - If no argument is passed, it uses the default value (0), adds 1, and returns 1.\n",
      "  - If a number is provided, it adds 1 to it and returns the result.\n",
      "\n",
      "**Example Usage**:\n",
      "- `add_one()` → returns `1`\n",
      "- `add_one(5)` → returns `6`\n",
      "- `add_one(-3)` → returns `-2`\n",
      "\n",
      "### Verification\n",
      "\n",
      "Let's ensure that the solution aligns with the problem statement:\n",
      "1. **With Input**: For any given number, it adds 1 and returns the result.\n",
      "2. **Without Input**: It starts with 0, adds 1, and returns 1.\n",
      "\n",
      "\\boxed{1} \n",
      "\n",
      "**Explanation of the Boxed Answer**:\n",
      "- Since no previous number is provided in the problem statement, according to the note, we start with 0.\n",
      "- Adding 1 to 0 gives us 1, which is the final answer to return.\n"
     ]
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "await Console(team.run_stream())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3addac6b",
   "metadata": {},
   "source": [
    "### Built-In Termination Conditions:\n",
    "\n",
    "- MaxMessageTermination: Stops after a specified number of messages have been produced, including both agent and task messages.\n",
    "\n",
    "- TextMentionTermination: Stops when specific text or string is mentioned in a message (e.g., “TERMINATE”).\n",
    "\n",
    "- TokenUsageTermination: Stops when a certain number of prompt or completion tokens are used. This requires the agents to report token usage in their messages.\n",
    "\n",
    "- TimeoutTermination: Stops after a specified duration in seconds.\n",
    "\n",
    "- HandoffTermination: Stops when a handoff to a specific target is requested. Handoff messages can be used to build patterns such as Swarm. This is useful when you want to pause the run and allow application or user to provide input when an agent hands off to them.\n",
    "\n",
    "- SourceMatchTermination: Stops after a specific agent responds.\n",
    "\n",
    "- ExternalTermination: Enables programmatic control of termination from outside the run. This is useful for UI integration (e.g., “Stop” buttons in chat interfaces).\n",
    "\n",
    "- StopMessageTermination: Stops when a StopMessage is produced by an agent.\n",
    "\n",
    "- TextMessageTermination: Stops when a TextMessage is produced by an agent.\n",
    "\n",
    "- FunctionCallTermination: Stops when a ToolCallExecutionEvent containing a FunctionExecutionResult with a matching name is produced by an agent.\n",
    "\n",
    "- FunctionalTermination: Stop when a function expression is evaluated to True on the last delta sequence of messages. This is useful for quickly create custom termination conditions that are not covered by the built-in ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18393e47",
   "metadata": {},
   "source": [
    "## Text Terminations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53195c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a story about a brave knight.\n",
      "---------- TextMessage (story_writer) ----------\n",
      "A brave knight, clad in shining armor, rescued a village from a fierce dragon. With courage and skill, he defeated the beast, earning the people's gratitude. His legend spread far and wide, inspiring hope in all who heard it.  \n",
      "\n",
      "THE END.  \n",
      "\n",
      "THE END\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a story about a brave knight.', type='TextMessage'), TextMessage(source='story_writer', models_usage=RequestUsage(prompt_tokens=46, completion_tokens=56), metadata={}, content=\"A brave knight, clad in shining armor, rescued a village from a fierce dragon. With courage and skill, he defeated the beast, earning the people's gratitude. His legend spread far and wide, inspiring hope in all who heard it.  \\n\\nTHE END.  \\n\\nTHE END\", type='TextMessage')], stop_reason=\"Text 'THE END' mentioned\")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "agent1 = AssistantAgent(\n",
    "    name = 'story_writer',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Give the story about a brave knight, keep it short no more than 40 words. if critic say 'THE END' anywhere. Only output 'THE END'\"\n",
    ")\n",
    "\n",
    "agent2 = AssistantAgent(\n",
    "    name = 'story_critic',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Continue the story and critic it with feedback. Keep it short and no more than 40 words. If it feels complete, just say 'THE END'. Only output 'THE END'\"\n",
    ")\n",
    "\n",
    "\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "\n",
    "\n",
    "text_mention_termination = TextMentionTermination('THE END')\n",
    "teamWithTextTermination = RoundRobinGroupChat(\n",
    "    [agent1, agent2],\n",
    "    termination_condition=text_mention_termination\n",
    ")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(teamWithTextTermination.run_stream(task = 'Write a story about a brave knight.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec47a6fb",
   "metadata": {},
   "source": [
    "# Combining Termination Conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a story about a brave knight.\n",
      "---------- TextMessage (story_writer) ----------\n",
      "Once, a brave knight rode into the cursed forest, sword gleaming, to save a stolen princess. Shadows whispered, yet he pressed on—defeating beasts and dark magic alike. At dawn, he returned victorious, her hand in his, hope restored.  \n",
      "\n",
      "THE END.  \n",
      "\n",
      "THE END.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a story about a brave knight.', type='TextMessage'), TextMessage(source='story_writer', models_usage=RequestUsage(prompt_tokens=113, completion_tokens=60), metadata={}, content='Once, a brave knight rode into the cursed forest, sword gleaming, to save a stolen princess. Shadows whispered, yet he pressed on—defeating beasts and dark magic alike. At dawn, he returned victorious, her hand in his, hope restored.  \\n\\nTHE END.  \\n\\nTHE END.', type='TextMessage')], stop_reason=\"Text 'THE END' mentioned\")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_termination = MaxMessageTermination(5) | TextMentionTermination('THE END') # (| for OR) and (& for AND)\n",
    "\n",
    "from autogen_agentchat.conditions import TextMentionTermination\n",
    "\n",
    "\n",
    "text_mention_termination = TextMentionTermination('THE END')\n",
    "teamWithTextTermination = RoundRobinGroupChat(\n",
    "    [agent1, agent2],\n",
    "    termination_condition=combined_termination\n",
    ")\n",
    "\n",
    "from autogen_agentchat.ui import Console\n",
    "\n",
    "await Console(teamWithTextTermination.run_stream(task = 'Write a story about a brave knight.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56717a9",
   "metadata": {},
   "source": [
    "## External Termination\n",
    "- ExternalTermination: Enables programmatic control of termination from outside the run. This is useful for UI integration (e.g., “Stop” buttons in chat interfaces)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc55eabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent1 = AssistantAgent(\n",
    "    name = 'story_writer',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Give the story about a brave knight, keep it short no more than 40 words. if critic say 'THE END' anywhere. Only output 'THE END'\"\n",
    ")\n",
    "\n",
    "agent2 = AssistantAgent(\n",
    "    name = 'story_critic',\n",
    "    model_client=model_client,\n",
    "    system_message=\"Continue the story and critic it with feedback. Keep it short and no more than 40 words. If it feels complete, just say 'THE END'. Only output 'THE END'\"\n",
    ")\n",
    "\n",
    "from autogen_agentchat.conditions import ExternalTermination\n",
    "external_termination = ExternalTermination()\n",
    "\n",
    "from autogen_agentchat.teams import RoundRobinGroupChat\n",
    "team = RoundRobinGroupChat(\n",
    "    [agent1, agent2],\n",
    "    termination_condition= external_termination\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be27f249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Write a story about a brave knight less than 40 words.\n",
      "---------- TextMessage (story_writer) ----------\n",
      "Sir Kael, though clad in rust-streaked armor, never hesitated. When bandits threatened his village, he charged atop his loyal, scarred mare. Outnumbered, he fought fiercely—his chipped sword flashing like lightning. Victory came, proving even worn heroes shine brightest in darkness. **THE END**\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskResult(messages=[TextMessage(source='user', models_usage=None, metadata={}, content='Write a story about a brave knight less than 40 words.', type='TextMessage'), TextMessage(source='story_writer', models_usage=RequestUsage(prompt_tokens=164, completion_tokens=64), metadata={}, content='Sir Kael, though clad in rust-streaked armor, never hesitated. When bandits threatened his village, he charged atop his loyal, scarred mare. Outnumbered, he fought fiercely—his chipped sword flashing like lightning. Victory came, proving even worn heroes shine brightest in darkness. **THE END**', type='TextMessage')], stop_reason='External termination requested')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.ui import Console\n",
    "run = asyncio.create_task(Console(team.run_stream(task = 'Write a story about a brave knight less than 40 words.'))) # we created a task\n",
    "\n",
    "await asyncio.sleep(0.2) # sleep\n",
    "\n",
    "external_termination.set() # stops only the current agent turn is over\n",
    "await run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfab5a05",
   "metadata": {},
   "source": [
    "- The team is not stopping immediately but rather current agent is completing its run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd785f82",
   "metadata": {},
   "source": [
    "## Aborting A Team\n",
    "- Different from stopping a team, aborting a team will immediately stop the team and raise a CancelledError exception."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aaaa12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- TextMessage (user) ----------\n",
      "Give a short Story about a lion atmost 40 words\n",
      "---------- TextMessage (story_critic) ----------\n",
      "**The Last Roar**  \n",
      "\n",
      "Old Leo, once king of the savanna, stood alone against a rival pride. Though weakened by age, his thunderous roar scattered the challengers—a final act of defiance. The grasslands remembered his reign. **THE END**  \n",
      "\n",
      "*Feedback:* Simple but powerful. Adds weight with age and legacy. Good tension in few words. Want a tweak?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error processing publish message for story_writer_b31642ac-91cb-4e74-ace9-a8e08b1fe583/b31642ac-91cb-4e74-ace9-a8e08b1fe583\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 2454, in create\n",
      "    return await self._post(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1791, in post\n",
      "    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\openai\\_base_client.py\", line 1526, in request\n",
      "    response = await self._client.send(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1629, in send\n",
      "    response = await self._send_handling_auth(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1657, in _send_handling_auth\n",
      "    response = await self._send_handling_redirects(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1694, in _send_handling_redirects\n",
      "    response = await self._send_single_request(request)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpx\\_client.py\", line 1730, in _send_single_request\n",
      "    response = await transport.handle_async_request(request)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpx\\_transports\\default.py\", line 394, in handle_async_request\n",
      "    resp = await self._pool.handle_async_request(req)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 256, in handle_async_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\connection_pool.py\", line 236, in handle_async_request\n",
      "    response = await connection.handle_async_request(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\connection.py\", line 103, in handle_async_request\n",
      "    return await self._connection.handle_async_request(request)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 136, in handle_async_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 106, in handle_async_request\n",
      "    ) = await self._receive_response_headers(**kwargs)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 177, in _receive_response_headers\n",
      "    event = await self._receive_event(timeout=timeout)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_async\\http11.py\", line 217, in _receive_event\n",
      "    data = await self._network_stream.read(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\httpcore\\_backends\\anyio.py\", line 35, in read\n",
      "    return await self._stream.receive(max_bytes=max_bytes)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\anyio\\streams\\tls.py\", line 219, in receive\n",
      "    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\anyio\\streams\\tls.py\", line 162, in _call_sslobject_method\n",
      "    data = await self.transport_stream.receive()\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 1254, in receive\n",
      "    await self._protocol.read_event.wait()\n",
      "  File \"C:\\Users\\shubu\\anaconda3\\lib\\asyncio\\locks.py\", line 214, in wait\n",
      "    await fut\n",
      "asyncio.exceptions.CancelledError\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_core\\_single_threaded_agent_runtime.py\", line 604, in _on_message\n",
      "    return await agent.on_message(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_core\\_base_agent.py\", line 119, in on_message\n",
      "    return await self.on_message_impl(message, ctx)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_sequential_routed_agent.py\", line 67, in on_message_impl\n",
      "    return await super().on_message_impl(message, ctx)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_core\\_routed_agent.py\", line 485, in on_message_impl\n",
      "    return await h(self, message, ctx)\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_core\\_routed_agent.py\", line 268, in wrapper\n",
      "    return_value = await func(self, message, ctx)  # type: ignore\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_agentchat\\teams\\_group_chat\\_chat_agent_container.py\", line 79, in handle_request\n",
      "    async for msg in self._agent.on_messages_stream(self._message_buffer, ctx.cancellation_token):\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 827, in on_messages_stream\n",
      "    async for inference_output in self._call_llm(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_agentchat\\agents\\_assistant_agent.py\", line 955, in _call_llm\n",
      "    model_result = await model_client.create(\n",
      "  File \"c:\\Users\\shubu\\Desktop\\AutoGen Hardcode\\venv\\lib\\site-packages\\autogen_ext\\models\\openai\\_openai_client.py\", line 624, in create\n",
      "    result: Union[ParsedChatCompletion[BaseModel], ChatCompletion] = await future\n",
      "asyncio.exceptions.CancelledError\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task Was Cancelled\n"
     ]
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "cancellation_token = CancellationToken() # cancle async pending calls\n",
    "\n",
    "run2 = asyncio.create_task(\n",
    "    Console(team.run_stream(task = 'Give a short Story about a lion atmost 40 words',cancellation_token=cancellation_token))\n",
    ")\n",
    "\n",
    "await asyncio.sleep(5)\n",
    "cancellation_token.cancel()\n",
    "\n",
    "try:\n",
    "    result = await run2\n",
    "except :\n",
    "    print(\"Task Was Cancelled\")  # it was giveing output but stopped at 5 sec. NOT WAITING FOR ANYONE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
